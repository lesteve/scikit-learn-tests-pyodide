(node:460160) ExperimentalWarning: Fetch is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
warning: no blob constructor, cannot create blobs with mimetypes
warning: no BlobBuilder
Loading distutils
Loaded distutils
Python initialization complete
(node:460160) ExperimentalWarning: buffer.Blob is an experimental feature. This feature could change at any time
distutils already loaded from default channel
Loading micropip, pyparsing, packaging
Loaded micropip, pyparsing, packaging
distutils already loaded from default channel
Loading scikit-learn, scipy, numpy, joblib, threadpoolctl, clapack
Loaded clapack, joblib, threadpoolctl, numpy, scikit-learn, scipy
distutils already loaded from default channel
pyparsing already loaded from default channel
Loading pytest, atomicwrites, attrs, six, more-itertools, pluggy, py, setuptools, iniconfig
Loaded atomicwrites, pytest, attrs, six, more-itertools, pluggy, py, iniconfig, setuptools
Loading tomli
Loaded tomli
pytest command: pytest.main("--pyargs sklearn._loss.tests -v".split())
[1m============================= test session starts ==============================[0m
platform emscripten -- Python 3.10.2, pytest-7.1.2, pluggy-1.0.0 -- 
cachedir: .pytest_cache
rootdir: /home/pyodide
[1mcollecting ... [0m[1mcollecting 0 items                                                             [0m[1mcollecting 1527 items                                                          [0m[1mcollected 1527 items                                                           [0m

test_glm_distribution.py::test_family_bounds[family0-expected0] [32mPASSED[0m[32m   [  0%][0m
test_glm_distribution.py::test_family_bounds[family1-expected1] [32mPASSED[0m[32m   [  0%][0m
test_glm_distribution.py::test_family_bounds[family2-expected2] [32mPASSED[0m[32m   [  0%][0m
test_glm_distribution.py::test_family_bounds[family3-expected3] [32mPASSED[0m[32m   [  0%][0m
test_glm_distribution.py::test_family_bounds[family4-expected4] [32mPASSED[0m[32m   [  0%][0m
test_glm_distribution.py::test_family_bounds[family5-expected5] [32mPASSED[0m[32m   [  0%][0m
test_glm_distribution.py::test_invalid_distribution_bound [32mPASSED[0m[32m         [  0%][0m
test_glm_distribution.py::test_tweedie_distribution_power [32mPASSED[0m[32m         [  0%][0m
test_glm_distribution.py::test_deviance_zero[family0-chk_values0] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family1-chk_values1] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family2-chk_values2] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family3-chk_values3] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family4-chk_values4] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family5-chk_values5] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family6-chk_values6] [32mPASSED[0m[32m [  0%][0m
test_glm_distribution.py::test_deviance_zero[family7-chk_values7] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_zero[family8-chk_values8] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[NormalDistribution] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[PoissonDistribution] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[GammaDistribution] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[InverseGaussianDistribution] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[TweedieDistribution0] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[TweedieDistribution1] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[TweedieDistribution2] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[TweedieDistribution3] [32mPASSED[0m[32m [  1%][0m
test_glm_distribution.py::test_deviance_derivative[TweedieDistribution4] [32mPASSED[0m[32m [  1%][0m
test_link.py::test_interval_raises [32mPASSED[0m[32m                                [  1%][0m
test_link.py::test_is_in_range[interval0] [32mPASSED[0m[32m                         [  1%][0m
test_link.py::test_is_in_range[interval1] [32mPASSED[0m[32m                         [  1%][0m
test_link.py::test_is_in_range[interval2] [32mPASSED[0m[32m                         [  1%][0m
test_link.py::test_is_in_range[interval3] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval4] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval5] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval6] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval7] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval8] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval9] [32mPASSED[0m[32m                         [  2%][0m
test_link.py::test_is_in_range[interval10] [32mPASSED[0m[32m                        [  2%][0m
test_link.py::test_is_in_range[interval11] [32mPASSED[0m[32m                        [  2%][0m
test_link.py::test_link_inverse_identity[IdentityLink] [32mPASSED[0m[32m            [  2%][0m
test_link.py::test_link_inverse_identity[LogLink] [32mPASSED[0m[32m                 [  2%][0m
test_link.py::test_link_inverse_identity[LogitLink] [32mPASSED[0m[32m               [  2%][0m
test_link.py::test_link_inverse_identity[MultinomialLogit] [32mPASSED[0m[32m        [  2%][0m
test_link.py::test_link_out_argument[IdentityLink] [32mPASSED[0m[32m                [  2%][0m
test_link.py::test_link_out_argument[LogLink] [32mPASSED[0m[32m                     [  2%][0m
test_link.py::test_link_out_argument[LogitLink] [32mPASSED[0m[32m                   [  3%][0m
test_link.py::test_link_out_argument[MultinomialLogit] [32mPASSED[0m[32m            [  3%][0m
test_loss.py::test_loss_boundary[HalfSquaredError] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[AbsoluteError] [32mPASSED[0m[32m                   [  3%][0m
test_loss.py::test_loss_boundary[PinballLoss0] [32mPASSED[0m[32m                    [  3%][0m
test_loss.py::test_loss_boundary[HalfPoissonLoss] [32mPASSED[0m[32m                 [  3%][0m
test_loss.py::test_loss_boundary[HalfGammaLoss] [32mPASSED[0m[32m                   [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLoss0] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfBinomialLoss] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfMultinomialLoss] [32mPASSED[0m[32m             [  3%][0m
test_loss.py::test_loss_boundary[PinballLoss1] [32mPASSED[0m[32m                    [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLoss1] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLoss2] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLoss3] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLoss4] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLoss5] [32mPASSED[0m[32m                [  3%][0m
test_loss.py::test_loss_boundary[HalfTweedieLossIdentity0] [32mPASSED[0m[32m        [  4%][0m
test_loss.py::test_loss_boundary[HalfTweedieLossIdentity1] [32mPASSED[0m[32m        [  4%][0m
test_loss.py::test_loss_boundary[HalfTweedieLossIdentity2] [32mPASSED[0m[32m        [  4%][0m
test_loss.py::test_loss_boundary[HalfTweedieLossIdentity3] [32mPASSED[0m[32m        [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss0-y_true_success0-y_true_fail0] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss1-y_true_success1-y_true_fail1] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss2-y_true_success2-y_true_fail2] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss3-y_true_success3-y_true_fail3] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss4-y_true_success4-y_true_fail4] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss5-y_true_success5-y_true_fail5] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss6-y_true_success6-y_true_fail6] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss7-y_true_success7-y_true_fail7] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss8-y_true_success8-y_true_fail8] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss9-y_true_success9-y_true_fail9] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss10-y_true_success10-y_true_fail10] [32mPASSED[0m[32m [  4%][0m
test_loss.py::test_loss_boundary_y_true[loss11-y_true_success11-y_true_fail11] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss12-y_true_success12-y_true_fail12] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss13-y_true_success13-y_true_fail13] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss14-y_true_success14-y_true_fail14] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss15-y_true_success15-y_true_fail15] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss16-y_true_success16-y_true_fail16] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss17-y_true_success17-y_true_fail17] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss18-y_true_success18-y_true_fail18] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss19-y_true_success19-y_true_fail19] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss20-y_true_success20-y_true_fail20] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss21-y_true_success21-y_true_fail21] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss22-y_true_success22-y_true_fail22] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss23-y_true_success23-y_true_fail23] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss24-y_true_success24-y_true_fail24] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_true[loss25-y_true_success25-y_true_fail25] [32mPASSED[0m[32m [  5%][0m
test_loss.py::test_loss_boundary_y_pred[loss0-y_pred_success0-y_pred_fail0] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss1-y_pred_success1-y_pred_fail1] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss2-y_pred_success2-y_pred_fail2] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss3-y_pred_success3-y_pred_fail3] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss4-y_pred_success4-y_pred_fail4] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss5-y_pred_success5-y_pred_fail5] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss6-y_pred_success6-y_pred_fail6] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss7-y_pred_success7-y_pred_fail7] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss8-y_pred_success8-y_pred_fail8] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss9-y_pred_success9-y_pred_fail9] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss10-y_pred_success10-y_pred_fail10] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss11-y_pred_success11-y_pred_fail11] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss12-y_pred_success12-y_pred_fail12] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss13-y_pred_success13-y_pred_fail13] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss14-y_pred_success14-y_pred_fail14] [32mPASSED[0m[32m [  6%][0m
test_loss.py::test_loss_boundary_y_pred[loss15-y_pred_success15-y_pred_fail15] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss16-y_pred_success16-y_pred_fail16] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss17-y_pred_success17-y_pred_fail17] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss18-y_pred_success18-y_pred_fail18] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss19-y_pred_success19-y_pred_fail19] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss20-y_pred_success20-y_pred_fail20] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss21-y_pred_success21-y_pred_fail21] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss22-y_pred_success22-y_pred_fail22] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss23-y_pred_success23-y_pred_fail23] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss24-y_pred_success24-y_pred_fail24] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_boundary_y_pred[loss25-y_pred_success25-y_pred_fail25] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_on_specific_values[HalfSquaredError-1.0-5.0-8] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_on_specific_values[AbsoluteError-1.0-5.0-4] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_on_specific_values[PinballLoss-1.0-5.0-2] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_on_specific_values[PinballLoss-1.0-5.0-3.0] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_on_specific_values[PinballLoss-5.0-1.0-1.0] [32mPASSED[0m[32m [  7%][0m
test_loss.py::test_loss_on_specific_values[HalfPoissonLoss-2.0-1.3862943611198906-1.2274112777602189] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfGammaLoss-2.0-1.3862943611198906-1.8862943611198906] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfTweedieLoss-2.0-1.3862943611198906--0.1875] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfTweedieLossIdentity-2.0-4.0-0.6137056388801094] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfTweedieLossIdentity-2.0-4.0-0.1931471805599453] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfTweedieLossIdentity-2.0-4.0-0.0625] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfBinomialLoss-0.25-1.3862943611198906-1.2628643221541276] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfMultinomialLoss-0.0-[0.2, 0.5, 0.3]-1.23983106084446] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfMultinomialLoss-1.0-[0.2, 0.5, 0.3]-0.93983106084446] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_on_specific_values[HalfMultinomialLoss-2.0-[0.2, 0.5, 0.3]-1.13983106084446] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-PinballLoss] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[32m [  8%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-PinballLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-PinballLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[32m [  9%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-PinballLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-PinballLoss] [32mPASSED[0m[32m [ 10%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-PinballLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-PinballLoss] [32mPASSED[0m[32m [ 11%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-PinballLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[32m [ 12%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-PinballLoss] [32mPASSED[0m[32m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[32m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[32m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[32m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[32m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[32m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 13%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 14%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 15%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 16%][0m
test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 17%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 18%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 19%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 20%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 21%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 22%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 23%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 24%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 25%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 26%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 27%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 28%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 29%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 30%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 31%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 32%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 33%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 34%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 35%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 36%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 37%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 38%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 39%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 40%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 41%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 42%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 43%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 44%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 45%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 46%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 47%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 48%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 49%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 50%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 51%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 52%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 53%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 54%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 55%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 56%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 57%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 58%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 59%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 60%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 61%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 62%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 63%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 64%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 65%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 66%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 67%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-PinballLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 68%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-PinballLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float32-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 69%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-HalfSquaredError] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-AbsoluteError] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-PinballLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-HalfGammaLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float32-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 70%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-HalfSquaredError] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-AbsoluteError] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-PinballLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-HalfPoissonLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-HalfGammaLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-HalfTweedieLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-HalfBinomialLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-None-float64-float64-True-HalfMultinomialLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-PinballLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 71%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-PinballLoss] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-PinballLoss] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 72%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-PinballLoss] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-HalfSquaredError] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-AbsoluteError] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-PinballLoss] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-HalfGammaLoss] [32mPASSED[0m[31m [ 73%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfSquaredError] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-AbsoluteError] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-PinballLoss] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfGammaLoss] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-HalfSquaredError] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-AbsoluteError] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-PinballLoss] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-HalfPoissonLoss] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-HalfGammaLoss] [32mPASSED[0m[31m [ 74%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-HalfTweedieLoss] [32mPASSED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-HalfBinomialLoss] [32mPASSED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-False-HalfMultinomialLoss] [32mPASSED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfSquaredError] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-AbsoluteError] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-PinballLoss] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfPoissonLoss] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfGammaLoss] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfTweedieLoss] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfBinomialLoss] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfMultinomialLoss] [31mFAILED[0m[31m [ 75%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfSquaredError] [32mPASSED[0m[31m [ 75%][0m
test_loss.py::test_loss_same_as_C_functions[None-AbsoluteError] [32mPASSED[0m[31m   [ 75%][0m
test_loss.py::test_loss_same_as_C_functions[None-PinballLoss0] [32mPASSED[0m[31m    [ 75%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfPoissonLoss] [32mPASSED[0m[31m [ 75%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfGammaLoss] [32mPASSED[0m[31m   [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLoss0] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfBinomialLoss] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-PinballLoss1] [32mPASSED[0m[31m    [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLoss1] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLoss2] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLoss3] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLoss4] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLoss5] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[None-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfSquaredError] [32mPASSED[0m[31m [ 76%][0m
test_loss.py::test_loss_same_as_C_functions[range-AbsoluteError] [32mPASSED[0m[31m  [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-PinballLoss0] [32mPASSED[0m[31m   [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfPoissonLoss] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfGammaLoss] [32mPASSED[0m[31m  [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLoss0] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfBinomialLoss] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-PinballLoss1] [32mPASSED[0m[31m   [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLoss1] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLoss2] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLoss3] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLoss4] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLoss5] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 77%][0m
test_loss.py::test_loss_same_as_C_functions[range-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfSquaredError] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-AbsoluteError] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-PinballLoss0] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfPoissonLoss] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfGammaLoss] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLoss0] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfBinomialLoss] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-PinballLoss1] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLoss1] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLoss2] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLoss3] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLoss4] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLoss5] [32mPASSED[0m[31m [ 78%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-None-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfSquaredError] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-AbsoluteError] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-PinballLoss0] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfPoissonLoss] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfGammaLoss] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLoss0] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfBinomialLoss] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-PinballLoss1] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLoss1] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLoss2] [32mPASSED[0m[31m [ 79%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLoss3] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLoss4] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLoss5] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_loss_gradients_are_the_same[42-range-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfSquaredError] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-AbsoluteError] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-PinballLoss0] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfPoissonLoss] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfGammaLoss] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLoss0] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfBinomialLoss] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfMultinomialLoss] [32mPASSED[0m[31m [ 80%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-PinballLoss1] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLoss1] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLoss2] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLoss3] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLoss4] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLoss5] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-ones-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfSquaredError] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-AbsoluteError] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-PinballLoss0] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfPoissonLoss] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfGammaLoss] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLoss0] [32mPASSED[0m[31m [ 81%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfBinomialLoss] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfMultinomialLoss] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-PinballLoss1] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLoss1] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLoss2] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLoss3] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLoss4] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLoss5] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_sample_weight_multiplies[42-random-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 82%][0m
test_loss.py::test_graceful_squeezing[HalfSquaredError] [32mPASSED[0m[31m           [ 82%][0m
test_loss.py::test_graceful_squeezing[AbsoluteError] [32mPASSED[0m[31m              [ 82%][0m
test_loss.py::test_graceful_squeezing[PinballLoss0] [32mPASSED[0m[31m               [ 82%][0m
test_loss.py::test_graceful_squeezing[HalfPoissonLoss] [32mPASSED[0m[31m            [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfGammaLoss] [32mPASSED[0m[31m              [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLoss0] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfBinomialLoss] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfMultinomialLoss] [32mPASSED[0m[31m        [ 83%][0m
test_loss.py::test_graceful_squeezing[PinballLoss1] [32mPASSED[0m[31m               [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLoss1] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLoss2] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLoss3] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLoss4] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLoss5] [32mPASSED[0m[31m           [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLossIdentity0] [32mPASSED[0m[31m   [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLossIdentity1] [32mPASSED[0m[31m   [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLossIdentity2] [32mPASSED[0m[31m   [ 83%][0m
test_loss.py::test_graceful_squeezing[HalfTweedieLossIdentity3] [32mPASSED[0m[31m   [ 83%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfSquaredError] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-AbsoluteError] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-PinballLoss0] [32mPASSED[0m[31m  [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfPoissonLoss] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfGammaLoss] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLoss0] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfBinomialLoss] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-PinballLoss1] [32mPASSED[0m[31m  [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLoss1] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLoss2] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLoss3] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLoss4] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLoss5] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 84%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[None-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfSquaredError] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-AbsoluteError] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-PinballLoss0] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfPoissonLoss] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfGammaLoss] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLoss0] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfBinomialLoss] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-PinballLoss1] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLoss1] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLoss2] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLoss3] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLoss4] [32mPASSED[0m[31m [ 85%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLoss5] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_loss_of_perfect_prediction[range-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfSquaredError] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-AbsoluteError] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-PinballLoss0] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfPoissonLoss] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfGammaLoss] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLoss0] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfBinomialLoss] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-PinballLoss1] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLoss1] [32mPASSED[0m[31m [ 86%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLoss2] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLoss3] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLoss4] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLoss5] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-None-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfSquaredError] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-AbsoluteError] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-PinballLoss0] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfPoissonLoss] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfGammaLoss] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLoss0] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfBinomialLoss] [32mPASSED[0m[31m [ 87%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-PinballLoss1] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLoss1] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLoss2] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLoss3] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLoss4] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLoss5] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_gradients_hessians_numerically[42-range-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 88%][0m
test_loss.py::test_derivatives[squared_error--2.0-42] [33mSKIPPED[0m (skipp...)[31m [ 88%][0m
test_loss.py::test_derivatives[squared_error-117.0-1.05] [33mSKIPPED[0m (sk...)[31m [ 88%][0m
test_loss.py::test_derivatives[squared_error-0.0-0.0] [33mSKIPPED[0m (skipp...)[31m [ 88%][0m
test_loss.py::test_derivatives[binomial_loss-0.3-0.1] [33mSKIPPED[0m (skipp...)[31m [ 88%][0m
test_loss.py::test_derivatives[binomial_loss--12-0.2] [33mSKIPPED[0m (skipp...)[31m [ 88%][0m
test_loss.py::test_derivatives[binomial_loss-30-0.9] [33mSKIPPED[0m (skippe...)[31m [ 89%][0m
test_loss.py::test_derivatives[poisson_loss-12.0-1.0] [33mSKIPPED[0m (skipp...)[31m [ 89%][0m
test_loss.py::test_derivatives[poisson_loss-0.0-2.0] [33mSKIPPED[0m (skippe...)[31m [ 89%][0m
test_loss.py::test_derivatives[poisson_loss--22.0-10.0] [33mSKIPPED[0m (ski...)[31m [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfSquaredError] [32mPASSED[0m[31m     [ 89%][0m
test_loss.py::test_loss_intercept_only[None-AbsoluteError] [32mPASSED[0m[31m        [ 89%][0m
test_loss.py::test_loss_intercept_only[None-PinballLoss0] [32mPASSED[0m[31m         [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfPoissonLoss] [32mPASSED[0m[31m      [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfGammaLoss] [32mPASSED[0m[31m        [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLoss0] [32mPASSED[0m[31m     [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfBinomialLoss] [32mPASSED[0m[31m     [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfMultinomialLoss] [32mPASSED[0m[31m  [ 89%][0m
test_loss.py::test_loss_intercept_only[None-PinballLoss1] [32mPASSED[0m[31m         [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLoss1] [32mPASSED[0m[31m     [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLoss2] [32mPASSED[0m[31m     [ 89%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLoss3] [32mPASSED[0m[31m     [ 90%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLoss4] [32mPASSED[0m[31m     [ 90%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLoss5] [32mPASSED[0m[31m     [ 90%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 90%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 90%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 90%][0m
test_loss.py::test_loss_intercept_only[None-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 90%][0m
test_loss.py::test_loss_intercept_only[range-HalfSquaredError] [32mPASSED[0m[31m    [ 90%][0m
test_loss.py::test_loss_intercept_only[range-AbsoluteError] [32mPASSED[0m[31m       [ 90%][0m
test_loss.py::test_loss_intercept_only[range-PinballLoss0] [32mPASSED[0m[31m        [ 90%][0m
test_loss.py::test_loss_intercept_only[range-HalfPoissonLoss] [32mPASSED[0m[31m     [ 90%][0m
test_loss.py::test_loss_intercept_only[range-HalfGammaLoss] [32mPASSED[0m[31m       [ 90%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLoss0] [32mPASSED[0m[31m    [ 90%][0m
test_loss.py::test_loss_intercept_only[range-HalfBinomialLoss] [32mPASSED[0m[31m    [ 90%][0m
test_loss.py::test_loss_intercept_only[range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 90%][0m
test_loss.py::test_loss_intercept_only[range-PinballLoss1] [32mPASSED[0m[31m        [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLoss1] [32mPASSED[0m[31m    [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLoss2] [32mPASSED[0m[31m    [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLoss3] [32mPASSED[0m[31m    [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLoss4] [32mPASSED[0m[31m    [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLoss5] [32mPASSED[0m[31m    [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLossIdentity0] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLossIdentity1] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLossIdentity2] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_loss_intercept_only[range-HalfTweedieLossIdentity3] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss0-mean-normal] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss1-median-normal] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss2-<lambda>-normal] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss3-mean-poisson] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss4-mean-exponential] [32mPASSED[0m[31m [ 91%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss5-mean-exponential] [32mPASSED[0m[31m [ 92%][0m
test_loss.py::test_specific_fit_intercept_only[42-loss6-mean-binomial] [32mPASSED[0m[31m [ 92%][0m
test_loss.py::test_multinomial_loss_fit_intercept_only [32mPASSED[0m[31m            [ 92%][0m
test_loss.py::test_binomial_and_multinomial_loss[42] [32mPASSED[0m[31m              [ 92%][0m
test_loss.py::test_predict_proba[42-HalfSquaredError] [32mPASSED[0m[31m             [ 92%][0m
test_loss.py::test_predict_proba[42-AbsoluteError] [32mPASSED[0m[31m                [ 92%][0m
test_loss.py::test_predict_proba[42-PinballLoss0] [32mPASSED[0m[31m                 [ 92%][0m
test_loss.py::test_predict_proba[42-HalfPoissonLoss] [32mPASSED[0m[31m              [ 92%][0m
test_loss.py::test_predict_proba[42-HalfGammaLoss] [32mPASSED[0m[31m                [ 92%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLoss0] [32mPASSED[0m[31m             [ 92%][0m
test_loss.py::test_predict_proba[42-HalfBinomialLoss] [32mPASSED[0m[31m             [ 92%][0m
test_loss.py::test_predict_proba[42-HalfMultinomialLoss] [32mPASSED[0m[31m          [ 92%][0m
test_loss.py::test_predict_proba[42-PinballLoss1] [32mPASSED[0m[31m                 [ 92%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLoss1] [32mPASSED[0m[31m             [ 92%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLoss2] [32mPASSED[0m[31m             [ 92%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLoss3] [32mPASSED[0m[31m             [ 92%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLoss4] [32mPASSED[0m[31m             [ 93%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLoss5] [32mPASSED[0m[31m             [ 93%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLossIdentity0] [32mPASSED[0m[31m     [ 93%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLossIdentity1] [32mPASSED[0m[31m     [ 93%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLossIdentity2] [32mPASSED[0m[31m     [ 93%][0m
test_loss.py::test_predict_proba[42-HalfTweedieLossIdentity3] [32mPASSED[0m[31m     [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-HalfSquaredError] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-AbsoluteError] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-PinballLoss] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-HalfPoissonLoss] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-HalfGammaLoss] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-HalfTweedieLoss] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-HalfBinomialLoss] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-HalfSquaredError] [32mPASSED[0m[31m [ 93%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-AbsoluteError] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-PinballLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-HalfPoissonLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-HalfGammaLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-HalfTweedieLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-HalfBinomialLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float32-range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-HalfSquaredError] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-AbsoluteError] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-PinballLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-HalfPoissonLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-HalfGammaLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-HalfTweedieLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-HalfBinomialLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 94%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-HalfSquaredError] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-AbsoluteError] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-PinballLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-HalfPoissonLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-HalfGammaLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-HalfTweedieLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-HalfBinomialLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[C-float64-range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-HalfSquaredError] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-AbsoluteError] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-PinballLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-HalfPoissonLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-HalfGammaLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-HalfTweedieLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-HalfBinomialLoss] [32mPASSED[0m[31m [ 95%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-HalfSquaredError] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-AbsoluteError] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-PinballLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-HalfPoissonLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-HalfGammaLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-HalfTweedieLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-HalfBinomialLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float32-range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-HalfSquaredError] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-AbsoluteError] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-PinballLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-HalfPoissonLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-HalfGammaLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-HalfTweedieLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-HalfBinomialLoss] [32mPASSED[0m[31m [ 96%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-None-HalfMultinomialLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-HalfSquaredError] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-AbsoluteError] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-PinballLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-HalfPoissonLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-HalfGammaLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-HalfTweedieLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-HalfBinomialLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessians[F-float64-range-HalfMultinomialLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-HalfSquaredError] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-AbsoluteError] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-PinballLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-HalfPoissonLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-HalfGammaLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-HalfTweedieLoss] [32mPASSED[0m[31m [ 97%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-HalfBinomialLoss] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_init_gradient_and_hessian_raises[params0-Valid options for 'dtype' are .* Got dtype=<class 'numpy.int64'> instead.-HalfMultinomialLoss] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_loss_init_parameter_validation[PinballLoss-params0-TypeError-quantile must be an instance of float, not NoneType.] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_loss_init_parameter_validation[PinballLoss-params1-ValueError-quantile == 0, must be > 0.] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_loss_init_parameter_validation[PinballLoss-params2-ValueError-quantile == 1.1, must be < 1.] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_loss_init_parameter_validation[HalfTweedieLoss-params3-TypeError-power must be an instance of float, not NoneType.] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_loss_init_parameter_validation[HalfTweedieLoss-params4-ValueError-power == inf, must be < inf.] [32mPASSED[0m[31m [ 98%][0m
test_loss.py::test_loss_pickle[HalfSquaredError] [32mPASSED[0m[31m                  [ 98%][0m
test_loss.py::test_loss_pickle[AbsoluteError] [32mPASSED[0m[31m                     [ 98%][0m
test_loss.py::test_loss_pickle[PinballLoss0] [32mPASSED[0m[31m                      [ 98%][0m
test_loss.py::test_loss_pickle[HalfPoissonLoss] [32mPASSED[0m[31m                   [ 98%][0m
test_loss.py::test_loss_pickle[HalfGammaLoss] [32mPASSED[0m[31m                     [ 98%][0m
test_loss.py::test_loss_pickle[HalfTweedieLoss0] [32mPASSED[0m[31m                  [ 98%][0m
test_loss.py::test_loss_pickle[HalfBinomialLoss] [32mPASSED[0m[31m                  [ 98%][0m
test_loss.py::test_loss_pickle[HalfMultinomialLoss] [32mPASSED[0m[31m               [ 98%][0m
test_loss.py::test_loss_pickle[PinballLoss1] [32mPASSED[0m[31m                      [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLoss1] [32mPASSED[0m[31m                  [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLoss2] [32mPASSED[0m[31m                  [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLoss3] [32mPASSED[0m[31m                  [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLoss4] [32mPASSED[0m[31m                  [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLoss5] [32mPASSED[0m[31m                  [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLossIdentity0] [32mPASSED[0m[31m          [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLossIdentity1] [32mPASSED[0m[31m          [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLossIdentity2] [32mPASSED[0m[31m          [ 99%][0m
test_loss.py::test_loss_pickle[HalfTweedieLossIdentity3] [32mPASSED[0m[31m          [ 99%][0m
test_loss.py::test_tweedie_log_identity_consistency[-1.5] [32mPASSED[0m[31m         [ 99%][0m
test_loss.py::test_tweedie_log_identity_consistency[0] [32mPASSED[0m[31m            [ 99%][0m
test_loss.py::test_tweedie_log_identity_consistency[1] [32mPASSED[0m[31m            [ 99%][0m
test_loss.py::test_tweedie_log_identity_consistency[1.5] [32mPASSED[0m[31m          [ 99%][0m
test_loss.py::test_tweedie_log_identity_consistency[2] [32mPASSED[0m[31m            [ 99%][0m
test_loss.py::test_tweedie_log_identity_consistency[3] [32mPASSED[0m[31m            [100%][0m

=================================== FAILURES ===================================
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float32-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x38ff148>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float32-float32-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3892158>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-None-1-float32-float32-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x33c82e8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float32-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x33cd020>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float32-float32-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x38d7e28>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float32-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3df6388>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float32-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3dcd178>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[1-None-None-1-float32-float32-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3cbfb00>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float64-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3d2f198>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float32-float64-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x33d1450>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-None-1-float32-float64-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3c05508>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float64-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x39e7968>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float32-float64-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x33367c8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float64-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3f6d8f8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float32-float64-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3fa75f0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[1-None-None-1-float32-float64-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x33a9570>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float32-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3b541f8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float64-float32-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3a4eec0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-None-1-float64-float32-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3e37140>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float32-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3b3f760>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float64-float32-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x33afe70>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float32-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3b4fe08>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float32-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3f058a8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[1-None-None-1-float64-float32-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3abe930>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float64-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3c524a8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float64-float64-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3c33bb8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-None-1-float64-float64-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3a81f80>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float64-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3e08568>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-None-1-float64-float64-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3c4aee8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float64-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x402e1b8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-None-1-float64-float64-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3c4aee8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[1-None-None-1-float64-float64-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x412b928>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float32-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3a44b40>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float32-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3b7c670>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-None-1-1-float32-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3b4d408>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float32-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3eb4238>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float32-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x39558d8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float32-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x40fc2f0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float32-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x33bdcb0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-1-1-float32-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3fa9410>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float32-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3a7f970>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float32-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3e49fb8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-None-1-1-float32-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3cb6318>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float32-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3ee6d08>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float32-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3acdb40>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float32-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3913218>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float32-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3e80e90>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-1-1-float32-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3bdaf58>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float64-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x4119780>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float64-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x39dadf0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-None-1-1-float64-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x41db770>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float64-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x40dfa00>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float64-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x41db0d0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float64-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3b24d58>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float64-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x41dede0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-1-1-float64-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3ba01a8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float64-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x40fc7d0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float64-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3893890>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-None-1-1-float64-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3a10570>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float64-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x41fc178>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-None-1-1-float64-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3f38420>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-None-1-1-float64-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x330f028>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-None-1-1-float64-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x22a4f30>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-None-1-1-float64-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x2275cc0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = None, n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float32-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3931700>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float32-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3fa96b0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-None-1-float32-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3eee410>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float32-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x442e9f0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float32-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3d546b8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float32-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3af0088>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float32-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3cc72c8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-1-None-1-float32-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x421e6c0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float32-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x33097c0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float32-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x414e168>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-None-1-float32-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3d38048>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float32-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3ebbe18>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float32-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3b9ba88>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float32-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x421f460>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float32-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x422f010>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-1-None-1-float32-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3cca2d0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float64-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x41096d0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float64-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x2276eb0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-None-1-float64-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x41c9390>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float64-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4178270>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float64-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3f28968>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float64-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3a96158>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float64-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3f261d8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-1-None-1-float64-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x44cfe58>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float64-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3c9e758>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float64-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3ecd5b0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-None-1-float64-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4168f18>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float64-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x425cd18>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-None-1-float64-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3efac10>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[1-1-None-1-float64-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x413b010>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-None-1-float64-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3f28fb8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[1-1-None-1-float64-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x34e2000>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float32-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x40fc1f8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float32-float32-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3bea018>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[1-1-1-1-float32-float32-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3ecd760>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float32-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3cd6228>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float32-float32-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x456e948>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float32-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x444a328>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float32-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3d543f8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-1-1-float32-float32-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x4448058>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float64-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x444a7b8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float32-float64-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3ab6388>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[1-1-1-1-float32-float64-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x444a958>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float64-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3eb0f58>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float32-float64-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x456de48>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float64-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3a724e0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float32-float64-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x4423000>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-1-1-float32-float64-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3e02fb0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float32-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x452fdd8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float64-float32-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x4507970>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[1-1-1-1-float64-float32-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4423ff0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float32-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x405f858>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float64-float32-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x450a5e0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float32-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x45aa5d8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float32-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x41db770>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-1-1-float64-float32-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3c2d280>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float64-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3d06fe8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float64-float64-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3db4b48>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[1-1-1-1-float64-float64-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4496bb8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float64-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4498c38>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[1-1-1-1-float64-float64-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3ac2540>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float64-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x468eb88>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[1-1-1-1-float64-float64-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x38ec610>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[1-1-1-1-float64-float64-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x45a8a28>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 1

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float32-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3fa6ea8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float32-float32-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x4445608>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-None-1-float32-float32-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x452f978>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float32-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3e24f88>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float32-float32-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x227b430>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float32-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x4445608>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float32-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x403ada0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[2-None-None-1-float32-float32-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3afb238>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float64-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x22b0fd8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float32-float64-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3b488f8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-None-1-float32-float64-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3b34ad0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float64-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4709b90>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float32-float64-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x421e388>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float64-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x474b260>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float32-float64-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x41f2538>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[2-None-None-1-float32-float64-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3b01370>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float32-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3facf18>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float64-float32-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x4708ee0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-None-1-float64-float32-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3b1c600>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float32-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4404880>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float64-float32-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x472d420>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float32-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x45b6c28>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float32-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x472b3d0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[2-None-None-1-float64-float32-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3d25030>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float64-True-HalfSquaredError] _____[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3d772a8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float64-float64-True-AbsoluteError] _______[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x41be0d8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-None-1-float64-float64-True-PinballLoss] ________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x45079d0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float64-True-HalfPoissonLoss] ______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x466a028>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-None-1-float64-float64-True-HalfGammaLoss] _______[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x476d3e8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float64-True-HalfTweedieLoss] ______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3c0cda8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-None-1-float64-float64-True-HalfBinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3b24760>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m___ test_loss_dtype[2-None-None-1-float64-float64-True-HalfMultinomialLoss] ____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x47000b0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None, out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float32-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3b05b98>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float32-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x4068260>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-None-1-1-float32-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3d6bb28>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float32-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3eb97f8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float32-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x47cbf00>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float32-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x44cc068>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float32-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x39eebf8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-1-1-float32-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3c7b2b0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float32-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3cfe388>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float32-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x47be840>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-None-1-1-float32-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3c56788>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32), out2 = None
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float32-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4165c48>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float32-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x230c760>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float32-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3c0b298>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float32-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x44a8178>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-1-1-float32-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3c40be8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float64-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3e7c9d0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float64-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x465d0f0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-None-1-1-float64-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4826b68>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float64-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x404a5b8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float64-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x46607b0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float64-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x48489c8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float64-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x465f6e0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-1-1-float64-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x48cc6a0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float64-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x48cb548>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float64-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x393a068>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-None-1-1-float64-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x49acc08>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float64-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x492dd40>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-None-1-1-float64-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x4132028>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-None-1-1-float64-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x49ae3e8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-None-1-1-float64-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x4826a40>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-None-1-1-float64-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x22c0490>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = None, n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float32-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x473cb58>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float32-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3be0f38>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-None-1-float32-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3738270>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float32-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3a5d760>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float32-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x47dfb50>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float32-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3f36e70>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float32-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x4938ea8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-1-None-1-float32-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3eeba88>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float32-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x49abcc8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float32-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x230c820>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-None-1-float32-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x3721070>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float32-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3a546d8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float32-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x48a5178>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float32-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3d06780>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float32-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x48a5108>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-1-None-1-float32-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x48a5358>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float64-float32-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x3a69cd8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float64-float32-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x4509008>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-None-1-float64-float32-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4989318>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float64-float32-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3c0b990>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float64-float32-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x4a8f0c0>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float64-float32-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x45b27c8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float64-float32-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x22c0ba8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-1-None-1-float64-float32-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3f36e70>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float64-float64-True-HalfSquaredError] _______[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x474b940>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float64-float64-True-AbsoluteError] ________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3f6c3b0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-None-1-float64-float64-True-PinballLoss] _________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4821650>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float64-float64-True-HalfPoissonLoss] _______[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3759808>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-None-1-float64-float64-True-HalfGammaLoss] ________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x49c2bf8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_______ test_loss_dtype[2-1-None-1-float64-float64-True-HalfTweedieLoss] _______[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x47df2a8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-None-1-float64-float64-True-HalfBinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x47bef38>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_____ test_loss_dtype[2-1-None-1-float64-float64-True-HalfMultinomialLoss] _____[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3eefea0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = None
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float32-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x496b880>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float32-float32-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x4a9c5b8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[2-1-1-1-float32-float32-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x47bb840>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float32-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4a9c490>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float32-float32-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x496b428>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float32-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x49ba140>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float32-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x4a9c5b8>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-1-1-float32-float32-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x3c5f590>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float64-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x4b6da58>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float32-float64-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x374dc10>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[2-1-1-1-float32-float64-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4baf068>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float64-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x4a69238>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float32-float64-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x3abbb30>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float64-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x4baf068>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float32-float64-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x4bec320>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([0., 0., 0., 0., 0.], dtype=float32)
out2 = array([0., 0., 0., 0., 0.], dtype=float32), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-1-1-float32-float64-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x41ef800>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float32'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]], dtype=float32)
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float32-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x45acd68>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float64-float32-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3cb8568>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[2-1-1-1-float64-float32-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x22c8c58>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float32-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x3bfb998>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float64-float32-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x4c09828>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float32-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x3f07a68>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.], dtype=float32), axis = None
weights = memmap([0., 0., 0., 0., 0.], dtype=float32), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float32-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x3782540>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = array([0., 0., 0., 0., 0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.6931472, 0.6931472, 0.6931472, 0.6931472, 0.6931472],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-1-1-float64-float32-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x4c09d00>
readonly_memmap = True, dtype_in = <class 'numpy.float32'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.], dtype=float32)
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.0986123, 1.0986123, 1.0986123, 1.0986123, 1.0986123],
      dtype=float32)
axis = None, weights = memmap([0., 0., 0., 0., 0.], dtype=float32)
returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float64-True-HalfSquaredError] ________[0m

loss = <sklearn._loss.loss.HalfSquaredError object at 0x4c2ee88>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float64-float64-True-AbsoluteError] __________[0m

loss = <sklearn._loss.loss.AbsoluteError object at 0x3aff950>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m__________ test_loss_dtype[2-1-1-1-float64-float64-True-PinballLoss] ___________[0m

loss = <sklearn._loss.loss.PinballLoss object at 0x4d0e1e0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = array([-0., -0., -0., -0., -0.]), out2 = array([0., 0., 0., 0., 0.])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float64-True-HalfPoissonLoss] _________[0m

loss = <sklearn._loss.loss.HalfPoissonLoss object at 0x37891a8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1., 1., 1., 1., 1.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m_________ test_loss_dtype[2-1-1-1-float64-float64-True-HalfGammaLoss] __________[0m

loss = <sklearn._loss.loss.HalfGammaLoss object at 0x458eee0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0., 0., 0., 0., 0.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float64-True-HalfTweedieLoss] _________[0m

loss = <sklearn._loss.loss.HalfTweedieLoss object at 0x45c5de8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([2., 2., 2., 2., 2.]), axis = None
weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m________ test_loss_dtype[2-1-1-1-float64-float64-True-HalfBinomialLoss] ________[0m

loss = <sklearn._loss.loss.HalfBinomialLoss object at 0x4d0e1e0>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.]), out1 = array([0., 0., 0., 0., 0.])
out2 = array([0., 0., 0., 0., 0.]), n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
[31m[1m______ test_loss_dtype[2-1-1-1-float64-float64-True-HalfMultinomialLoss] _______[0m

loss = <sklearn._loss.loss.HalfMultinomialLoss object at 0x46487e8>
readonly_memmap = True, dtype_in = <class 'numpy.float64'>
dtype_out = <class 'numpy.float64'>
sample_weight = memmap([0., 0., 0., 0., 0.])
out1 = memmap([[-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.],
        [-0.,  0.,  0.]])
out2 = array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
n_threads = 2

    @pytest.mark.parametrize("loss", ALL_LOSSES)
    @pytest.mark.parametrize("readonly_memmap", [False, True])
    @pytest.mark.parametrize("dtype_in", [np.float32, np.float64])
    @pytest.mark.parametrize("dtype_out", [np.float32, np.float64])
    @pytest.mark.parametrize("sample_weight", [None, 1])
    @pytest.mark.parametrize("out1", [None, 1])
    @pytest.mark.parametrize("out2", [None, 1])
    @pytest.mark.parametrize("n_threads", [1, 2])
    def test_loss_dtype(
        loss, readonly_memmap, dtype_in, dtype_out, sample_weight, out1, out2, n_threads
    ):
        """Test acceptance of dtypes, readonly and writeable arrays in loss functions.
    
        Check that loss accepts if all input arrays are either all float32 or all
        float64, and all output arrays are either all float32 or all float64.
    
        Also check that input arrays can be readonly, e.g. memory mapped.
        """
        loss = loss()
        # generate a y_true and raw_prediction in valid range
        n_samples = 5
        y_true, raw_prediction = random_y_true_raw_prediction(
            loss=loss,
            n_samples=n_samples,
            y_bound=(-100, 100),
            raw_bound=(-10, 10),
            seed=42,
        )
        y_true = y_true.astype(dtype_in)
        raw_prediction = raw_prediction.astype(dtype_in)
    
        if sample_weight is not None:
            sample_weight = np.array([2.0] * n_samples, dtype=dtype_in)
        if out1 is not None:
            out1 = np.empty_like(y_true, dtype=dtype_out)
        if out2 is not None:
            out2 = np.empty_like(raw_prediction, dtype=dtype_out)
    
        if readonly_memmap:
            y_true = create_memmap_backed_data(y_true, aligned=True)
            raw_prediction = create_memmap_backed_data(raw_prediction, aligned=True)
            if sample_weight is not None:
                sample_weight = create_memmap_backed_data(sample_weight, aligned=True)
    
        loss.loss(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            n_threads=n_threads,
        )
        loss.gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out2,
            n_threads=n_threads,
        )
        loss.loss_gradient(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            loss_out=out1,
            gradient_out=out2,
            n_threads=n_threads,
        )
        if out1 is not None and loss.is_multiclass:
            out1 = np.empty_like(raw_prediction, dtype=dtype_out)
        loss.gradient_hessian(
            y_true=y_true,
            raw_prediction=raw_prediction,
            sample_weight=sample_weight,
            gradient_out=out1,
            hessian_out=out2,
            n_threads=n_threads,
        )
>       loss(y_true=y_true, raw_prediction=raw_prediction, sample_weight=sample_weight)

[1m[31m/lib/python3.10/site-packages/sklearn/_loss/tests/test_loss.py[0m:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
[1m[31m/lib/python3.10/site-packages/sklearn/_loss/loss.py[0m:407: in __call__
    return np.average(
[1m[31m<__array_function__ internals>[0m:180: in average
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

a = array([1.09861229, 1.09861229, 1.09861229, 1.09861229, 1.09861229])
axis = None, weights = memmap([0., 0., 0., 0., 0.]), returned = False

    @array_function_dispatch(_average_dispatcher)
    def average(a, axis=None, weights=None, returned=False):
        """
        Compute the weighted average along the specified axis.
    
        Parameters
        ----------
        a : array_like
            Array containing data to be averaged. If `a` is not an array, a
            conversion is attempted.
        axis : None or int or tuple of ints, optional
            Axis or axes along which to average `a`.  The default,
            axis=None, will average over all of the elements of the input array.
            If axis is negative it counts from the last to the first axis.
    
            .. versionadded:: 1.7.0
    
            If axis is a tuple of ints, averaging is performed on all of the axes
            specified in the tuple instead of a single axis or all the axes as
            before.
        weights : array_like, optional
            An array of weights associated with the values in `a`. Each value in
            `a` contributes to the average according to its associated weight.
            The weights array can either be 1-D (in which case its length must be
            the size of `a` along the given axis) or of the same shape as `a`.
            If `weights=None`, then all data in `a` are assumed to have a
            weight equal to one.  The 1-D calculation is::
    
                avg = sum(a * weights) / sum(weights)
    
            The only constraint on `weights` is that `sum(weights)` must not be 0.
        returned : bool, optional
            Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)
            is returned, otherwise only the average is returned.
            If `weights=None`, `sum_of_weights` is equivalent to the number of
            elements over which the average is taken.
    
        Returns
        -------
        retval, [sum_of_weights] : array_type or double
            Return the average along the specified axis. When `returned` is `True`,
            return a tuple with the average as the first element and the sum
            of the weights as the second element. `sum_of_weights` is of the
            same type as `retval`. The result dtype follows a genereal pattern.
            If `weights` is None, the result dtype will be that of `a` , or ``float64``
            if `a` is integral. Otherwise, if `weights` is not None and `a` is non-
            integral, the result type will be the type of lowest precision capable of
            representing values of both `a` and `weights`. If `a` happens to be
            integral, the previous rules still applies but the result dtype will
            at least be ``float64``.
    
        Raises
        ------
        ZeroDivisionError
            When all weights along axis are zero. See `numpy.ma.average` for a
            version robust to this type of error.
        TypeError
            When the length of 1D `weights` is not the same as the shape of `a`
            along axis.
    
        See Also
        --------
        mean
    
        ma.average : average for masked arrays -- useful if your data contains
                     "missing" values
        numpy.result_type : Returns the type that results from applying the
                            numpy type promotion rules to the arguments.
    
        Examples
        --------
        >>> data = np.arange(1, 5)
        >>> data
        array([1, 2, 3, 4])
        >>> np.average(data)
        2.5
        >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))
        4.0
    
        >>> data = np.arange(6).reshape((3,2))
        >>> data
        array([[0, 1],
               [2, 3],
               [4, 5]])
        >>> np.average(data, axis=1, weights=[1./4, 3./4])
        array([0.75, 2.75, 4.75])
        >>> np.average(data, weights=[1./4, 3./4])
        Traceback (most recent call last):
            ...
        TypeError: Axis must be specified when shapes of a and weights differ.
    
        >>> a = np.ones(5, dtype=np.float128)
        >>> w = np.ones(5, dtype=np.complex64)
        >>> avg = np.average(a, weights=w)
        >>> print(avg.dtype)
        complex256
        """
        a = np.asanyarray(a)
    
        if weights is None:
            avg = a.mean(axis)
            scl = avg.dtype.type(a.size/avg.size)
        else:
            wgt = np.asanyarray(weights)
    
            if issubclass(a.dtype.type, (np.integer, np.bool_)):
                result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')
            else:
                result_dtype = np.result_type(a.dtype, wgt.dtype)
    
            # Sanity checks
            if a.shape != wgt.shape:
                if axis is None:
                    raise TypeError(
                        "Axis must be specified when shapes of a and weights "
                        "differ.")
                if wgt.ndim != 1:
                    raise TypeError(
                        "1D weights expected when shapes of a and weights differ.")
                if wgt.shape[0] != a.shape[axis]:
                    raise ValueError(
                        "Length of weights not compatible with specified axis.")
    
                # setup wgt to broadcast along axis
                wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)
                wgt = wgt.swapaxes(-1, axis)
    
            scl = wgt.sum(axis=axis, dtype=result_dtype)
            if np.any(scl == 0.0):
>               raise ZeroDivisionError(
                    "Weights sum to zero, can't be normalized")
[1m[31mE               ZeroDivisionError: Weights sum to zero, can't be normalized[0m

[1m[31m/lib/python3.10/site-packages/numpy/lib/function_base.py[0m:524: ZeroDivisionError
=========================== short test summary info ============================
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-None-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-None-1-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-None-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[1-1-1-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-None-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-None-1-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-None-1-float64-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float32-float64-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float32-True-HalfMultinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfSquaredError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-AbsoluteError]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-PinballLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfPoissonLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfGammaLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfTweedieLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfBinomialLoss]
FAILED test_loss.py::test_loss_dtype[2-1-1-1-float64-float64-True-HalfMultinomialLoss]
[31m=========== [31m[1m256 failed[0m, [32m1262 passed[0m, [33m9 skipped[0m[31m in 129.89s (0:02:09)[0m[31m ============[0m
